---
layout: archive
title: ""
permalink: /publications/
author_profile: true
redirect_from:
  - /resume
---
 
## <span style="color:grey"><b style="font-size:20px"> 0/1 Loss Optimization</b></span> 
---

* <font size=3>Shenglong Zhou, Lili Pan, Naihua Xiu and Houduo Qi, 2021 <br>
  <i>Quadratic convergence of Newton's method for 0/1 loss optimization</i>,
  <a href="https://www.researchgate.net/publication/350442413">ResearchGate</a></font>
  
* <font size=3>Shenglong Zhou, Lili Pan and Naihua Xiu, 2020 <br>
  <i>Heaviside set constrained optimization: optimality and Newton method</i>,
  <a href="https://www.researchgate.net/publication/343362652">ResearchGate</a>,
  <a href="https://arxiv.org/abs/2007.15737">ArXiv</a></font>
  
* <details markdown="1"> 
  <summary><b style="font-size:10px">Click for more papers</b></summary> 
    
  * <font size=3>Shenglong Zhou, Ziyan Luo and Naihua Xiu, 2021 <br> 
    <i>Computing one-bit compressive sensing via double-sparsity constrained optimization</i>,
    <a href="https://www.researchgate.net/publication/348371863">ResearchGate</a>,
    <a href="https://arxiv.org/abs/2101.03599">ArXiv</a>,
    <a href="https://github.com/ShenglongZhou/GPSP">Code</a></font>

  * <font size=3>Huajun Wang, Yuanhai Shao, Shenglong Zhou, Ce Zhang and Naihua Xiu, 2019 <br>
    <i>Support vector machine classifier via L0/1 soft-margin loss</i>,
    <a href="https://www.researchgate.net/publication/338717629">ResearchGate</a>,
    <a href="https://arxiv.org/abs/1912.07418">ArXiv</a>,
    <a href="https://github.com/Huajun-Wang/L01ADMM">Code</a></font>
     
  </details> 
 


## <span style="color:grey"><b style="font-size:20px">Sparse Optimization</b></span>
---

* <font size=3> Shenglong Zhou, Naihua Xiu and Houduo Qi, Journal of Machine Learning Research, 22(12):1−45, 2021<br>
  <i>Global and quadratic convergence of Newton hard-thresholding pursuit</i>,
  <a href="https://jmlr.org/papers/v22/19-026.html">JMLR</a>, 
  <a href="https://www.researchgate.net/publication/330224407">ResearchGate</a>, 
  <a href="https://arxiv.org/abs/1901.02763">ArXiv</a>, 
  <a href="https://github.com/ShenglongZhou/NHTPver2">Code</a></font>
  
* <font size=3> Shenglong Zhou, Lili Pan and Naihua Xiu,  Numerical Algorithms, 2021 <br>
  <i>Newton method  for L0-regularized optimization</i>,
  <a href="https://doi.org/10.1007/s11075-021-01085-x">NumAlg</a>, 
  <a href="https://www.researchgate.net/publication/340563338">ResearchGate</a>, 
  <a href="https://arxiv.org/abs/2004.05132">ArXiv</a>, 
  <a href="https://github.com/ShenglongZhou/NL0R">Code</a></font>
  
* <details markdown="1"> 
  <summary><b style="font-size:10px">Click for more papers</b></summary> 
    
  * <font size=3>Shenglong Zhou, Lili Pan, Mu Li and Meijuan Shang, SIAM Journal on Scientific Computing, 43(2), A772–A799, 2021 <br>
    <i>Newton hard-thresholding pursuit for sparse LCP via a new merit function</i>,
    <a href="https://doi.org/10.1137/19M1301539">SISC</a>, 
    <a href="https://www.researchgate.net/publication/337948990">ResearchGate</a>,
    <a href="https://arxiv.org/abs/2004.02244">ArXiv</a>,
    <a href="https://github.com/ShenglongZhou/NHTPver2">Code</a></font>


  * <font size=3>Shenglong Zhou, 2020 <br>
    <i>Sparse SVM for sufficient data reduction</i>,
    <a href="https://www.researchgate.net/publication/341883040">ResearchGate</a>,
    <a href="https://arxiv.org/abs/2005.13771">ArXiv</a>,
    <a href="https://github.com/ShenglongZhou/NSSVM">Code</a></font>

  * <font size=3>Xinrong Li, Naihua Xiu and  Shenglong Zhou, Journal of Optimization Theory and Applications, 184, 895–930, 2019 <br>
    <i>Matrix optimization over low-rank spectral sets: stationary points, local and global minimizers</i>,
    <a href="https://link.springer.com/article/10.1007%2Fs10957-019-01606-8">JOTA</a>,
    <a href="https://www.researchgate.net/publication/327581904">ResearchGate</a></font>

  * <font size=3>Rui Wang, Naihua Xiu and  Shenglong Zhou, 2021 <br>
    <i>Newton method for sparse logistic regression: quadratic convergence and extensive simulations</i>,
    <a href="https://www.researchgate.net/publication/330224305">ResearchGate</a>,
    <a href="https://arxiv.org/abs/1901.02768">ArXiv</a>,
    <a href="https://github.com/ShenglongZhou/NSLR">Code</a></font>

  * <font size=3>Lili Pan,  Shenglong Zhou, Naihua Xiu and Houduo Qi,Pacific Journal of Optimization, vol. 13(2): 325-353, 2017 <br>
    <i>A convergent iterative hard thresholding for sparsity and nonnegativity constrained optimization</i>,
    <a href="http://www.yokohamapublishers.jp/online2/oppjo/vol13/p325.html">PJO</a>,
    <a href="https://www.researchgate.net/publication/299519906">ResearchGate</a>,
    <a href="https://arxiv.org/abs/1406.7178">ArXiv</a>,
    <a href="https://github.com/ShenglongZhou/IIHT">Code</a></font>

  * <font size=3>Lianjun Zhang, Lingchen Kong and  Shenglong Zhou,Journal of Industrial and Management Optimization, vol. 13 (1): 93 - 112, 2017 <br>
    <i>A smoothing iterative method for quantile regression with nonconvex lp Penalty</i>,
    <a href="https://aimsciences.org/article/doi/10.3934/jimo.2016006">JIMO</a></font>

  * <font size=3>Yanqing Liu, Guokai Liu, Xianchao Xiu and  Shenglong Zhou,Pacific Journal of Optimization, vol. 13(2): 279-300, 2017 <br>
    <i>The $L_1$-penalized quantile regression for traditional Chinese medicine syndrome manifestation</i>,
    <a href="http://www.yokohamapublishers.jp/online2/oppjo/vol13/p279.html">PJO</a></font>

  * <font size=3>Shenglong Zhou, Naihua Xiu, YingnanWang, Lingchen Kong and Houduo Qi, Information and Inference, vol. 5(1): 76-102, 2016 <br>
    <i>A Null-space-based weighted l1 minimization approach to compressed sensing</i>,
    <a href="https://academic.oup.com/imaiai/article/5/1/76/2357109">IMAIAI</a>,
    <a href="https://www.researchgate.net/publication/294109268">ResearchGate</a>,
    <a href="https://github.com/ShenglongZhou/MIRL1">Code</a></font>

  * <font size=3>Lili Pan, Naihua Xiu and  Shenglong Zhou, Journal of the Operations Research Society of China, vol. 3(4): 421-439, 2015 <br>
    <i>On Solutions of Sparsity Constrained Optimization</i>,
    <a href="https://link.springer.com/article/10.1007/s40305-015-0101-3">JORSC</a></font>

  * <font size=3>Shenglong Zhou, Naihua Xiu, Ziyan Luo and Lingchen Kong, Journal of the Operations Research Society of China, vol. 3(2): 231-250, 2015 <br>
    <i>Sparse and low-rank covariance matrix estimation</i>,
    <a href="https://link.springer.com/article/10.1007/s40305-014-0058-7">JORSC</a>,
    <a href="https://github.com/ShenglongZhou/ADMM">Code</a></font>

  * <font size=3>Meijuan Shang, Shenglong Zhou and Naihua Xiu, Journal of Inequalities and Applications, vol. 34, 2015 <br>
    <i>Extragradient thresholding methods For sparse solutions of co-coercive NCPs</i>,
    <a href="https://journalofinequalitiesandapplications.springeropen.com/articles/10.1186/s13660-015-0551-5">JIA</a></font>

  * <font size=3>Meijuan Shang, Chao Zhang, Dingtao Peng and  Shenglong Zhou,Optimization Letters, vol. 9(6): 1231-1245, 2015 <br>
    <i>A half thresholding projection algorithm for sparse solutions of LCPs</i>,
    <a href="https://www.infona.pl/resource/bwmeta1.element.springer-doi-10_1007-S11590-014-0834-7">OPLE</a>,
    <a href="https://github.com/ShenglongZhou/HTPCP">Code</a></font>

  * <font size=3>Shenglong Zhou, Lingchen Kong and Naihua Xiu, Journal of the Operations Research Society of China, vol. 1(2): 227-237, 2013 <br>
    <i>New bounds for RIC in compressed sensing</i>,
    <a href="https://link.springer.com/article/10.1007/s40305-013-0013-z">JORSC</a></font>

  </details> 


## <span style="color:grey"><b style="font-size:20px">EDM Optimization</b></span>
---

* <font size=3> Shenglong Zhou, Naihua Xiu and Houduo Qi, Mathematical Programming Computation, 12(3): 337–387, 2019<br>
  <i>Robust euclidean embedding via EDM optimization</i>, 
  <a href="https://link.springer.com/article/10.1007/s12532-019-00168-0">MPC</a>,
  <a href="https://github.com/ShenglongZhou/PREEEDM">Code</a></font>
 
* Shenglong Zhou, Naihua Xiu and Houduo Qi, IEEE Transactions on Signal Processing, vol. 66(16): 4331-4346, 2018<br> 
  <i>A fast matrix majorization-projection method for penalized stress minimization with box constraints</i>,
  <a href="https://ieeexplore.ieee.org/document/8399531">TSP</a>,
  <a href="https://github.com/ShenglongZhou/SQREDM">Code</a></font>
  
* <details markdown="1"> 
  <summary><b style="font-size:10px">Click for more papers</b></summary>  
  
  * Shenglong Zhou, Naihua Xiu and Houduo Qi, PhD Thesis, University of Southampton, 2018<br>
    <i>Majorization-projection methods for multidimensional scaling via Euclidean distance matrix optimization</i>,
    <a href="https://eprints.soton.ac.uk/429739/">Soton</a></font>
  
  </details> 



## <span style="color:grey"><b style="font-size:20px">Bilevel Optimization</b></span>
---

* <font size=3> Alain Zemkoho and  Shenglong Zhou, Computational Optimization and Application, 78(2), 625-674, 2021 <br>
  <i>Theoretical and numerical comparison of the Karush-Kuhn-Tucker and value function reformulations in bilevel optimization</i>,
  <a href="https://doi.org/10.1007/s10589-020-00250-7">JCOA</a>,
  <a href="https://www.researchgate.net/publication/340769764">ResearchGate</a>,
  <a href="https://arxiv.org/abs/2004.10830">ArXiv</a></font>
 
  
* Shenglong Zhou, Alain Zemkoho and Andrey Tin, Bilevel optimization: advances and next challenges, 2019 <br> 
  <i>BOLIB 2019: Bilevel Optimization LIBrary of Test Problems Version 2</i>,
  <a href="https://biopt.github.io/files/Paper.pdf">BiOpt</a>,
  <a href="https://www.springer.com/gp/book/9783030521189">Book</a>, 
  <a href="https://www.researchgate.net/publication/338375731">ResearchGate</a>,
  <a href="https://arxiv.org/abs/1812.00230">ArXiv</a>,
  <a href="https://biopt.github.io/bolib/">Code</a></font>

 * <details markdown="1"> 
   <summary><b style="font-size:10px">Click for more papers</b></summary> 
  
   * <font size=3> Andreas Fischer, Alain Zemkoho and  Shenglong Zhou, 2019 <br>
     <i>Semismooth Newton-type method for bilevel optimization: Global convergence and extensive numerical experiments</i>,
     <a href="https://www.researchgate.net/publication/337943979">ResearchGate</a>,
     <a href="https://arxiv.org/abs/1912.07079">ArXiv</a></font>
  
  </details> 
